{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  #cv2 is the opencv library\n",
    "import matplotlib.pyplot as plt  #this library is for datavisualization\n",
    "import numpy as np   #this contain basic math function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.To read and disply the image\n",
    "cv2.imread(path)\n",
    "\n",
    "cv2.imshow(name,variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')   #to read image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)   #to show the image\n",
    "\n",
    "cv2.waitKey(0)   #it shows the image untill you press the enter\n",
    "cv2.destroyAllWindows()  #it close all the existing windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.To read and display the video using webcam\n",
    "hasframe,frame=cam.read()\n",
    "\n",
    "* hasframe- it tells weather the next frame is availabel or not (True or False)\n",
    "\n",
    "* frame - it gives the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)  # 0 for primary camera and 1 for secondary camera\n",
    "while True:\n",
    "    hasframe,frame=cam.read()\n",
    "    cv2.imshow('image',frame)\n",
    "    if cv2.waitKey(1)==13:  #if user press enter then exit from the loop\n",
    "        break\n",
    "cv2.destroyAllWindows()  #it close opened windows\n",
    "cam.release()   #it release the usage of camera "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Histogram \n",
    "cv2.calcHist(image,[channel],mask,[histsize],[range])\n",
    "\n",
    "* image - input image \n",
    "\n",
    "* channel - red,green or blue\n",
    "\n",
    "* mask - If we want to apply mask or not\n",
    "\n",
    "* histsize - size of an hist or bin\n",
    "\n",
    "* range - [starting range , ending range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13245ad7630>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "a=cv2.calcHist(img,[0],None,[256],[0,256])\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using matplot library \n",
    "flatten_image=img.ravel() - it returns the array of image with single dimention\n",
    "\n",
    "plt.hist(flatten_image,bins,range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()   #used to display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To draw line\n",
    "cv2.line(image,starting_point,ending_point,color,thickness)\n",
    "\n",
    "* image - input image\n",
    "\n",
    "* starting_point-(x-value,y-value)\n",
    "\n",
    "* ending_point - (x-value,y-value)\n",
    "\n",
    "* color - (blue,green,red)\n",
    "* thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.line(image,(0,0),(512,512),(0,255,0),5) \n",
    "cv2.imshow('preview',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To draw rectangle\n",
    "cv2.rectangle(image,point1,point2,color,thickness)\n",
    "* imgae - input image\n",
    "* point1 - top left corner point (x-value,y-value)\n",
    "* point2 - bottom right point (x-value,y-value)\n",
    "* color - (blue,green,red)\n",
    "* thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.rectangle(image,(100,100),(300,300),(127,50,127),15)\n",
    "cv2.imshow('preview',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To draw circle\n",
    "cv2.circle(image,center,radius,color,thickness)\n",
    "* image - input image\n",
    "* center - center of the circle (x-value,y-value)\n",
    "* radius - radius of the circle\n",
    "* color - (blue,green,red)\n",
    "* thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.circle(image,(100,100),50,(255,123,123),-1)#image,center point, radius,colour,thickness\n",
    "cv2.imshow('preview',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To put text on a image\n",
    "cv2.putText(image,text,starting_point,Font,Font-size,color,thickness)\n",
    "* image - input image\n",
    "* text - in string format\n",
    "* starting point - bottom left of the text (x-value,y-value)\n",
    "* Font \n",
    "* Font_size\n",
    "* color\n",
    "* thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.putText(image,'Hello',(300,300),cv2.FONT_HERSHEY_COMPLEX,2,(123,123,123),3)\n",
    "cv2.imshow('preview',image)     #image,text,starting_bottom_left,Font,Font_size,color,thickness\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Translation\n",
    "Translation means moving the image.\n",
    "cv2.warpAffine(image,matrix,shape)\n",
    "* image - input image\n",
    "* matrix  \n",
    "          1 0 Tx\n",
    "          0 1 Ty\n",
    " * Tx - how much shift along x-axis\n",
    " * Ty - how much shift along y-axis\n",
    "* shape-(height,width) of a input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "height,width=img.shape[:2]\n",
    "Ty,Tx=height/4,width/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=np.float32([[1,0,Tx],[0,1,Ty]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,   0.  ,  97.75],\n",
       "       [  0.  ,   1.  , 167.5 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_image=cv2.warpAffine(img,T,(height,width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('transformed image',t_image)\n",
    "cv2.imshow('Original image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Rotation \n",
    "cv2.getRotationMatrix2D(center,angle,scale)\n",
    "* center - center of the image with respect to that point rotation occurs\n",
    "* angle - angle of rotation\n",
    "* scale - basically what it does is zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "height,width=img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=cv2.getRotationMatrix2D((height/4,width/4),90,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_image=cv2.warpAffine(img,T,(height,width))\n",
    "cv2.imshow('transformed image',t_image)\n",
    "cv2.imshow('Original image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Resizing\n",
    "cv2.resize(image,dsize,fx,fy,interpolation)\n",
    "* image - input image\n",
    "* dsize - (x-resolution,y-resolution)\n",
    "* fx - it reduse horizontal pixels (0.5 means 50 percenatge)\n",
    "* fy - it reduse vertical pixels\n",
    "* interpolation - rezing method\n",
    " * cv2.INTER_AREA - good for shrinking or down sampling\n",
    " * cv2.INTER_NEAREST - Fastest \n",
    " * cv2.INTER_LINEAR - Good for zooming and up sampling\n",
    " * cv2.INTER_CUBIC - Better\n",
    " * cv2.INTER_LANCZOS4 - Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the command run to understand\n",
    "img=cv2.imread('test.jpeg')\n",
    "cv2.imshow('Original',img)\n",
    "#img=cv2.resize(img,dsize=(1024,1024))                        #it resize with own dimention\n",
    "#img=cv2.resize(img,dsize=None,fx=1,fy=1)                     #it gives original image\n",
    "#img=cv2.resize(img,dsize=None,fx=0.5,fy=0.5)                 #it reduse size by half\n",
    "img=cv2.resize(img,dsize=None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)  \n",
    "cv2.imshow('transformed',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "cv2.imshow('Original',img)\n",
    "#img=cv2.pyrDown(img)            #reduse the image size by half\n",
    "img=cv2.pyrUp(img)               #increase the image size by half\n",
    "cv2.imshow('transformed',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Non Affine Transform \n",
    "Non Affine Transform does not preserve parallelism,length and angle\n",
    "\n",
    "M=cv2.getPerspectiveTransform(source_point,des_point)\n",
    "* source_point - region selected from the original image\n",
    "* des_point - selected region is saved with in des_point\n",
    "\n",
    "cv2.warpPerspective(image,M,dsize)\n",
    "* image - input image size\n",
    "* M - matrix\n",
    "* dsize - output image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.00239600e-01,  7.68379944e-02, -6.73494391e+01],\n",
       "       [ 3.12233663e-02,  8.61764909e-01, -7.56229931e+01],\n",
       "       [ 1.44460943e-04,  4.24326941e-04,  1.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "cv2.imshow('Original',img)\n",
    "pts1 = np.float32([[76,85],[490,70],[520,520],[35,512]])\n",
    "pts2 = np.float32([[0,0],[300,0],[300,300], [0,300]])\n",
    "\n",
    "M=cv2.getPerspectiveTransform(pts1,pts2)\n",
    "image=cv2.warpPerspective(img,M,(420,420))## output image size\n",
    "cv2.imshow('transformed',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "M                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert BGR image to Gray scale image\n",
    "\n",
    "cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('test.jpeg')\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('preview',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Arithmetic operation \n",
    "Before doing arithmetic operation three condition must be satisfied \n",
    "1. Dimention of two images must be equal\n",
    "2. Number of channels must be same\n",
    "3. Pixel datatype is also need to be same\n",
    "\n",
    "Both Addition and multiplication increases brightness.Substration and Division decreases brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('test.jpeg')\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('preview',image)\n",
    "img=np.ones((670,391),order=np.uint8) *200\n",
    "img1=np.ones((670,391),order=np.uint8) *2\n",
    "img=img.astype('uint8')\n",
    "img1=img1.astype('uint8')\n",
    "\n",
    "\n",
    "#res=cv2.add(image,img)\n",
    "#res=cv2.subtract(image,img)\n",
    "#res=cv2.multiply(image,img1)\n",
    "res=cv2.divide(image,img1)\n",
    "\n",
    "\n",
    "cv2.imshow('after performing operation',res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.Bitwise operation\n",
    "It perform bitwise operation in every pixels in the image. In case of xor if both pixel value is **same** then result is **zero** and if pixel values are **different** and the result is **one** ."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If we want good result then use black and white images\n",
    "cv2.bitwise_and(image1,image2)\n",
    "cv2.bitwise_not(image)\n",
    "cv2.bitwise_or(image1,image2)\n",
    "cv2.bitwise_xor(image1,image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.Blurring \n",
    "Blurring reduse the sharp edges in the image\n",
    "\n",
    "cv2.filter2D(image,ddepth,kernel)\n",
    "* image - input image\n",
    "* ddepth - represent the depth of the output image\n",
    "* kernel - represent the convolution kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurring by applying own filter\n",
    "img=cv2.imread('test.jpeg')\n",
    "kernel=np.ones((7,7),np.float32)/49\n",
    "img1=cv2.filter2D(img,-1,kernel)\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('blured',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of Filters and blurring\n",
    "* Average blurring\n",
    "* Gaussian blurring\n",
    "* Median blurring\n",
    "* Bilateral filter\n",
    "* Box filter\n",
    "* SQRbox filter\n",
    "\n",
    "For clear explation click  [here](https://www.tutorialspoint.com/opencv/opencv_blur_averaging.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "\n",
    "#img1=cv2.blur(img,(3,3))              #average blur\n",
    "#img1=cv2.GaussianBlur(img,(7,7),0)    #gaussian blur\n",
    "#img1=cv2.medianBlur(img,5)            #median blur\n",
    "img1=cv2.bilateralFilter(img,9,75,75)  #sutable for noice removal\n",
    "\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('blured',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.Sharpening\n",
    "Sharpening is opposite to blurring.\n",
    "\n",
    "Kernel for sharpening is \n",
    "                        \n",
    "                 -1 -1 -1                      \n",
    "                 -1  9 -1                        \n",
    "                 -1 -1 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "kernel=np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "img1=cv2.filter2D(img,-1,kernel)\n",
    "cv2.imshow('box',img1)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.Thresholding\n",
    "Thresholding means convert a image into binary image that is image having the only pixel value of **zero** and **one**.\n",
    "Before applying thresholding we need to convert the image into gray scale image.\n",
    "\n",
    "cv2.threshold(image,threshold,maxvalue,mode)\n",
    "* image - input image\n",
    "* threshold - below this value is going to zero and above this value is going to one\n",
    "* maxvalue - maximum value we want to apply threshold\n",
    "* mode - different mode of applying threshold\n",
    " * cv2.THRESH_BINARY\n",
    " * cv2.THRESH_BINARY_INV\n",
    " * cv2.THRESH_MASK\n",
    " * cv2.THRESH_OTSU\n",
    " * cv2.THRESH_TOZERO\n",
    " * cv2.THRESH_TOZERO_INV\n",
    " * cv2.THRESH_TRIANGLE\n",
    " * cv2.THRESH_TRUNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img1=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('image',img1[1])\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.Dilation and Erosion\n",
    "* Dilation means size of an object in white shade or bright shade increases, while the size of an object in black shade or dark shade decreases.\n",
    "* Erosion means the size of an object in dark shade or black shade increases, while it decreases in white shade or bright shade.\n",
    "* cv2.erode(image,kernel,iterations)\n",
    "* cv2.dilate(image,kernel,iterations)\n",
    " * image - input image\n",
    " * kernel - convolution kernel\n",
    " * iterations - number of iteration we want to do\n",
    "* Increase or decrease the kernel size to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test.jpeg')\n",
    "kernel=np.ones((9,9),np.uint8)    \n",
    "\n",
    "img1=cv2.erode(img,kernel,iterations=1)\n",
    "#img1=cv2.dilate(img,kernel,iterations=1)\n",
    "\n",
    "cv2.imshow('image',img1)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection algorithms \n",
    "Most comman edge detection algorithms are\n",
    "* Sobel\n",
    "* Laplacian\n",
    "* Canny\n",
    "\n",
    "For Sobel and Laplacian we need to perform gray acale and thresholding operation before applying the filter. For canny no needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sobel Edge Detection \n",
    "img1=cv2.imread('testimage1.jpg')\n",
    "img=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)                  \n",
    "res,img=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "sobel_x=cv2.Sobel(img,6,0,1,ksize=5)  # This give horizontal edges in the image\n",
    "sobel_y=cv2.Sobel(img,6,1,0,ksize=5)  # This give vertical edges in the image\n",
    "sobel=cv2.bitwise_or(sobel_x,sobel_y) # This combine both edges\n",
    "\n",
    "cv2.imshow('Combine',sobel)\n",
    "cv2.imshow('vertical',sobel_y)\n",
    "cv2.imshow('horizontal',sobel_x)\n",
    "cv2.imshow('original',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detection\n",
    "img=cv2.imread('testimage1.jpg')\n",
    "canny=cv2.Canny(img,100,200)\n",
    "cv2.imshow('canny',canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Edge Detection\n",
    "img=cv2.imread('testimage1.jpg')\n",
    "\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "res,img=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "laplacian=cv2.Laplacian(img,cv2.CV_64F)\n",
    "\n",
    "\n",
    "cv2.imshow('filter',laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.CV_64F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
